# -*- coding: utf-8 -*-
"""rand3d_pretrained.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12YyWAqro3cy3iOCzntDbUnRV8SMREHse
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install -q git+https://github.com/rwightman/pytorch-image-models
!pip install -q --upgrade visualpriors scikit-learn
!git clone https://github.com/ColinConwell/DeepMouseTrap
# %cd DeepMouseTrap

from warnings import filterwarnings
filterwarnings('ignore')

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
from scipy import stats
from glob import glob
from PIL import Image
from sklearn.decomposition import PCA
from tqdm.auto import tqdm as tqdm
import os, sys, pickle
from plotnine import *
sys.path.append('..')
sys.path.append('model_opts')
np.random.seed(3)
import cv2

# Commented out IPython magic to ensure Python compatibility.
# %cd model_opts/
from feature_extraction import *
from model_options import *

def make_df(assets):
  dictlist = []
  label_counts = {}
  for asset in assets:
      imgstr = asset.split('/')[3]
      shape = int(imgstr[7:9])
      alpha = float(imgstr[12:15])
      if imgstr[16:18] == 't1':
        theta = -float(imgstr[19:22]) / 2
      elif imgstr[16:18] == 't2':
        theta = float(imgstr[19:22]) / 2
      else:
        theta = 0
      if imgstr[16:18] == 'p1':
        phi = -float(imgstr[19:22]) / 2
      elif imgstr[16:18] == 'p2':
        phi = float(imgstr[19:22]) / 2
      else:
        phi = 0
      row = {'image_name': imgstr, 'image_shape': shape, 'theta': theta, 'phi': phi}
      dictlist.append(row)
  df = pd.DataFrame(dictlist)
  return df

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
# %ls
from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!unzip Test224.zip -d /content/

images = [cv2.imread(file) for file in glob('/content/Test/*.png')]

fig, axes = plt.subplots(2, 3, sharex=True, sharey=True) 
for img, ax in zip(images[:6], axes.flat):
    ax.imshow(img)
    ax.axis('off')

assets = glob('/content/Test/*.png')
df = make_df(assets)
shapes = np.unique(df.image_shape)
thetas = np.unique(abs(df.theta))[1:]
phis = np.unique(abs(df.phi))[1:]
nshapes, nthetas, nphis = np.size(shapes), np.size(thetas), np.size(phis)

def init_model(model_string, model_options):
  model_name = model_options[model_string]['model_name']
  train_type = model_options[model_string]['train_type']
  model_call = model_options[model_string]['call']
  image_transforms = get_recommended_transforms(model_string, input_type = 'numpy')
  model = eval(model_call)
  model = model.eval()
  if torch.cuda.is_available():
    model = model.cuda()
  return model, image_transforms

def get_feature_maps(model, images):
  model_inputs = Variable(torch.stack([image_transforms(img) for img in images]))
  feature_maps = get_all_feature_maps(model, model_inputs)
  return feature_maps

def compute_dist(feature_maps):
  model_dist = {}
  for model_layer in tqdm(feature_maps):
    activity = feature_maps[model_layer]
    nstimuli, nfeatures = np.shape(activity)
    pca = PCA(n_components=10)
    pcs = pca.fit_transform(activity)
    model_dist[model_layer] = np.zeros((nstimuli,nstimuli))
    for i in range(nstimuli):
      for j in range(nstimuli):
        model_dist[model_layer][i,j] = np.sqrt(((pcs[i] - pcs[j]) ** 2).sum())
  return model_dist

def compute_rdms(feature_maps):
  model_rdms = {}
  for model_layer in tqdm(feature_maps):
    activity = feature_maps[model_layer]
    model_rdms[model_layer] = np.corrcoef(activity)
  return model_rdms

def analyse_dist(feature_maps, model_dist):
  dist_dtheta, dist_dphi = {}, {}
  for model_layer in tqdm(feature_maps):
    dist_dtheta[model_layer], dist_dphi[model_layer] = np.zeros((nshapes, nthetas)), np.zeros((nshapes, nphis))
    for shape in shapes:
      count = 0
      for theta in thetas:
        indx = df.index[(df.image_shape == shape) & (df.phi == 0) & (abs(df.theta) == theta)].to_list()
        dist_dtheta[model_layer][shape, count] = model_dist[model_layer][indx[0],indx[1]]
        count += 1
      count = 0
      for phi in phis:
        indx = df.index[(df.image_shape == shape) & (df.theta == 0) & (abs(df.phi) == phi)].to_list()
        dist_dphi[model_layer][shape, count] = model_dist[model_layer][indx[0],indx[1]]
        count += 1
  return dist_dtheta, dist_dphi

def analyse_rdms(feature_maps, model_rdms):
  rdms_dtheta, rdms_dphi = {}, {}
  for model_layer in tqdm(feature_maps):
    rdms_dtheta[model_layer], rdms_dphi[model_layer] = np.zeros((nshapes, nthetas)), np.zeros((nshapes, nphis))
    for shape in shapes:
      count = 0
      for theta in thetas:
        indx = df.index[(df.image_shape == shape) & (df.phi == 0) & (abs(df.theta) == theta)].to_list()
        rdms_dtheta[model_layer][shape, count] = model_rdms[model_layer][indx[0],indx[1]]
        count += 1
      count = 0
      for phi in phis:
        indx = df.index[(df.image_shape == shape) & (df.theta == 0) & (abs(df.phi) == phi)].to_list()
        rdms_dphi[model_layer][shape, count] = model_rdms[model_layer][indx[0],indx[1]]
        count += 1
  return rdms_dtheta, rdms_dphi

def compute_distcorr(feature_maps, dist_dtheta, dist_dphi):
  r, p = {}, {}
  angular_diff = np.expand_dims(np.concatenate((2*thetas, 2*phis)), axis=1).repeat(10, axis=1)
  for model_layer in feature_maps.keys():
    feature_dist = np.concatenate((dist_dtheta[model_layer].transpose(), dist_dphi[model_layer].transpose()))
    r[model_layer], p[model_layer] = stats.pearsonr(angular_diff.flatten(), feature_dist.flatten())
  return r, p

def compute_rdmscorr(feature_maps, rdms_dtheta, rdms_dphi):
  r, p = {}, {}
  angular_diff = np.expand_dims(np.concatenate((2*thetas, 2*phis)), axis=1).repeat(10, axis=1)
  for model_layer in feature_maps.keys():
    feature_dist = np.concatenate((rdms_dtheta[model_layer].transpose(), rdms_dphi[model_layer].transpose()))
    r[model_layer], p[model_layer] = stats.pearsonr(angular_diff.flatten(), feature_dist.flatten())
  return r, p

def plot_distcorr(feature_maps, dist_dtheta, dist_dphi):
  angular_diff = np.expand_dims(np.concatenate((2*thetas, 2*phis)), axis=1).repeat(10, axis=1)
  fig, axes = plt.subplots(2, 6, sharex=False, sharey=False, figsize=(16,6)) 
  for model_layer, ax in zip(feature_maps.keys(), axes.flat):
    feature_dist = np.concatenate((dist_dtheta[model_layer].transpose(), dist_dphi[model_layer].transpose()))
    r, p = stats.pearsonr(angular_diff.flatten(), feature_dist.flatten())
    sns.regplot(angular_diff.flatten(), feature_dist.flatten(), ax=ax, marker='o', scatter_kws={'s':3})
    ax.text(.05, .8, 'r={:.2f}'.format(r), transform=ax.transAxes)
    ax.set(xlim=(0, 180))

def plot_rdmscorr(feature_maps, rdms_dtheta, rdms_dphi):
  angular_diff = np.expand_dims(np.concatenate((2*thetas, 2*phis)), axis=1).repeat(10, axis=1)
  fig, axes = plt.subplots(2, 6, sharex=False, sharey=False, figsize=(16,6)) 
  for model_layer, ax in zip(feature_maps.keys(), axes.flat):
    feature_dist = np.concatenate((rdms_dtheta[model_layer].transpose(), rdms_dphi[model_layer].transpose()))
    r, p = stats.pearsonr(angular_diff.flatten(), feature_dist.flatten())
    sns.regplot(angular_diff.flatten(), feature_dist.flatten(), ax=ax, marker='o', scatter_kws={'s':3})
    ax.text(.05, .8, 'r={:.2f}'.format(r), transform=ax.transAxes)
    ax.set(xlim=(0, 180))

def analyse_convlayers(r_dist):
  r, r0, r_dist_convlayers = [], [], {}
  for modelname in r_dist.keys():
    for layername in r_dist[modelname].keys():
      if 'Conv' in layername:
        if not 'random' in modelname: 
          r.append(r_dist[modelname][layername])
        else:
          r0.append(r_dist[modelname][layername])
  if len(r0) == 0: r0 = 1
  r_dist_convlayers[model_strings[0]] = [r, r0, np.array(r) / np.array(r0)]
  return r_dist_convlayers

if not 'r_dist' in locals():
  dist_dtheta, dist_dphi, rdms_dtheta, rdms_dphi = {}, {}, {}, {}
  r_dist, p_dist, r_rdms, p_rdms = {}, {}, {}, {}

model_options = get_model_options()

#model_strings = ['alexnet_imagenet', 'alexnet_random', 
                 #'vgg19_imagenet', 'vgg19_random', 
                 #'resnet18_imagenet', 'resnet18_random', 
                 #'densenet121_imagenet', 'densenet121_random', 
                 #'squeezenet1_1_imagenet', 'squeezenet1_1_random',
                 #'mobilenet_v2_imagenet', 'mobilenet_v2_random',
                 #'inception_v3_imagenet', 'inception_v3_random'
#                 ]

model_strings = ['vgg11_imagenet']
for string in model_strings:
  model, image_transforms = init_model(string, model_options)
  feature_maps = get_feature_maps(model, images)
  model_dist = compute_dist(feature_maps)
  model_rdms = compute_rdms(feature_maps)

  dist_dtheta[string], dist_dphi[string], rdms_dtheta[string], rdms_dphi[string] = {}, {}, {}, {}
  dist_dtheta[string], dist_dphi[string] = analyse_dist(feature_maps, model_dist)
  rdms_dtheta[string], rdms_dphi[string] = analyse_rdms(feature_maps, model_rdms)

  r_dist[string], p_dist[string], r_rdms[string], p_rdms[string] = {}, {}, {}, {}
  r_dist[string], p_dist[string] = compute_distcorr(feature_maps, dist_dtheta[string], dist_dphi[string])
  r_rdms[string], p_rdms[string] = compute_rdmscorr(feature_maps, rdms_dtheta[string], rdms_dphi[string])

r_dist_convlayers = analyse_convlayers(r_dist)

import pickle
# Saving the objects:
with open('/content/vgg11.pkl', 'wb') as f:
  pickle.dump([dist_dtheta, dist_dphi, rdms_dtheta, rdms_dphi, 
                 r_dist, r_rdms, p_dist, p_rdms, r_dist_convlayers], f)

import pickle
# Loading the objects:
with open('/content/alexnet.pkl', 'rb') as f:
  dist_dtheta, dist_dphi, rdms_dtheta, rdms_dphi, r_dist, r_rdms, p_dist, p_rdms, r_dist_convlayers = pickle.load(f)

plot_distcorr(feature_maps, dist_dtheta['vgg11_imagenet'], dist_dphi['vgg11_imagenet'])
plot_distcorr(feature_maps, rdms_dtheta['vgg11_imagenet'], rdms_dphi['vgg11_imagenet'])

files.download('results.pkl')